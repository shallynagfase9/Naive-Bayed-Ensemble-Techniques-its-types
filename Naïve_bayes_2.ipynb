{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZAggymo4weYYIgZVgVsRP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shallynagfase9/Naive-Bayes-Ensemble-Techniques-its-types/blob/main/Na%C3%AFve_bayes_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. A company conducted a survey of its employees and found that 70% of the employees use the\n",
        "company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the\n",
        "probability that an employee is a smoker given that he/she uses the health insurance plan?"
      ],
      "metadata": {
        "id": "Xe52hgrSLp-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The problem states directly that 40% of the employees who use the health insurance plan are smokers. This conditional probability is P(S|H) = 0.40.\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "mMvyc1QCLqki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
      ],
      "metadata": {
        "id": "ia0drRrmMJZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Bernoulli Naive Bayes and Multinomial Naive Bayes are two types of Naive Bayes classifiers that are suitable for different kinds of data and applications. Here are the key differences between them:\n",
        "\n",
        "Bernoulli Naive Bayes-\n",
        "Data Type: Designed for binary/boolean features. Each feature is either 0 or 1.\n",
        "\n",
        "Multinomial Naive Bayes\n",
        "Data Type: Designed for discrete count features. Each feature represents the count or frequency of an attribute.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qyi1MqXGMLKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. How does Bernoulli Naive Bayes handle missing values?"
      ],
      "metadata": {
        "id": "4HUccEpUMZEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Bernoulli Naive Bayes, like other Naive Bayes classifiers, relies on the presence or absence of features (binary values, 0 or 1) to compute probabilities. Handling missing values in this context can be challenging since the model expects each feature to have a binary value. Here are some common strategies to handle missing values when using Bernoulli Naive Bayes:\n",
        "1. Imputation\n",
        "2. Ignoring Missing Values\n",
        "3. Missing Indicator\n",
        "4. Modeling Missingness\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rLdB-FoFMa3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
      ],
      "metadata": {
        "id": "KSs2atZqMtB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Gaussian Naive Bayes for Multi-class Classification\n",
        "Gaussian Naive Bayes assumes that the continuous features in the dataset follow a Gaussian (normal) distribution. It's particularly effective when dealing with numerical data where each classâ€™s features are assumed to be drawn from a Gaussian distribution.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "v9HXWMF_MuyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Assignment:\n",
        "Data preparation:\n",
        "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
        "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
        "is spam or not based on several input features.\n",
        "Implementation:\n",
        "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
        "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
        "dataset. You should use the default hyperparameters for each classifier.\n",
        "Results:\n",
        "Report the following performance metrics for each classifier:\n",
        "Accuracy\n",
        "Precision\n",
        "Recall\n",
        "F1 score\n",
        "Discussion:\n",
        "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
        "the case? Are there any limitations of Naive Bayes that you observed?\n",
        "Conclusion:\n",
        "Summarise your findings and provide some suggestions for future work."
      ],
      "metadata": {
        "id": "BL_z6gKSM09q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Load the Spambase dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
        "columns = [\n",
        "    \"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\", \"word_freq_our\",\n",
        "    \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\", \"word_freq_order\", \"word_freq_mail\",\n",
        "    \"word_freq_receive\", \"word_freq_will\", \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\",\n",
        "    \"word_freq_free\", \"word_freq_business\", \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\",\n",
        "    \"word_freq_your\", \"word_freq_font\", \"word_freq_000\", \"word_freq_money\", \"word_freq_hp\", \"word_freq_hpl\",\n",
        "    \"word_freq_george\", \"word_freq_650\", \"word_freq_lab\", \"word_freq_labs\", \"word_freq_telnet\",\n",
        "    \"word_freq_857\", \"word_freq_data\", \"word_freq_415\", \"word_freq_85\", \"word_freq_technology\",\n",
        "    \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\", \"word_freq_cs\",\n",
        "    \"word_freq_meeting\", \"word_freq_original\", \"word_freq_project\", \"word_freq_re\", \"word_freq_edu\",\n",
        "    \"word_freq_table\", \"word_freq_conference\", \"char_freq_;\", \"char_freq_(\", \"char_freq_[\", \"char_freq_!\",\n",
        "    \"char_freq_$\", \"char_freq_#\", \"capital_run_length_average\", \"capital_run_length_longest\",\n",
        "    \"capital_run_length_total\", \"is_spam\"\n",
        "]\n",
        "\n",
        "df = pd.read_csv(url, header=None, names=columns)\n",
        "\n",
        "# Prepare the data: Features and Target\n",
        "X = df.drop(columns=['is_spam'])\n",
        "y = df['is_spam']\n",
        "\n",
        "# Initialize Naive Bayes classifiers\n",
        "models = {\n",
        "    'Bernoulli Naive Bayes': BernoulliNB(),\n",
        "    'Multinomial Naive Bayes': MultinomialNB(),\n",
        "    'Gaussian Naive Bayes': make_pipeline(StandardScaler(), GaussianNB())\n",
        "}\n",
        "\n",
        "# Define cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Evaluate each model\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    scores_accuracy = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
        "    scores_precision = cross_val_score(model, X, y, cv=kf, scoring='precision')\n",
        "    scores_recall = cross_val_score(model, X, y, cv=kf, scoring='recall')\n",
        "    scores_f1 = cross_val_score(model, X, y, cv=kf, scoring='f1')\n",
        "\n",
        "    results[name] = {\n",
        "        'Accuracy': scores_accuracy.mean(),\n",
        "        'Precision': scores_precision.mean(),\n",
        "        'Recall': scores_recall.mean(),\n",
        "        'F1 Score': scores_f1.mean()\n",
        "    }\n",
        "\n",
        "# Print results\n",
        "print(\"Performance Metrics:\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xU3AJjJAM3rr",
        "outputId": "b1c1c6d5-8d1e-4d96-9493-d68ab2d05f76"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance Metrics:\n",
            "\n",
            "Bernoulli Naive Bayes:\n",
            "Accuracy: 0.8852\n",
            "Precision: 0.8844\n",
            "Recall: 0.8159\n",
            "F1 Score: 0.8480\n",
            "\n",
            "Multinomial Naive Bayes:\n",
            "Accuracy: 0.7914\n",
            "Precision: 0.7407\n",
            "Recall: 0.7218\n",
            "F1 Score: 0.7304\n",
            "\n",
            "Gaussian Naive Bayes:\n",
            "Accuracy: 0.8166\n",
            "Precision: 0.6945\n",
            "Recall: 0.9530\n",
            "F1 Score: 0.8025\n"
          ]
        }
      ]
    }
  ]
}