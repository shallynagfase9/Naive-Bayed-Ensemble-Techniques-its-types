{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyjPMcP1D8ISS3YIWarV9Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shallynagfase9/Naive-Bayes-Ensemble-Techniques-its-types/blob/main/Ensemble_Techniques_And_Its_Types_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Random Forest Regressor?"
      ],
      "metadata": {
        "id": "wB6wVCVUWmKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "A Random Forest Regressor is a type of ensemble learning method used for regression tasks.\n",
        "It belongs to the broader class of Random Forest models, which are based on the ensemble learning technique called bagging (Bootstrap Aggregating) and specifically utilize decision trees as base learners.\n",
        "\n",
        "\"\"\"\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Oylu6cQWmnx",
        "outputId": "f7e889c5-8cdd-4a05-da3d-e4317a61b357"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 2621.793155098221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. How does Random Forest Regressor reduce the risk of overfitting?"
      ],
      "metadata": {
        "id": "LOqSRRLcW84K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The Random Forest Regressor's ability to reduce overfitting stems from its ensemble approach, where multiple decision trees are trained on varied subsets of data with randomized feature selection.\n",
        "This diversity and averaging of predictions lead to improved generalization and robustness, making Random Forests a powerful tool in regression tasks where mitigating overfitting is critical for accurate predictions on unseen data.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "SL1Z6FWZW-_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?"
      ],
      "metadata": {
        "id": "ACgHLeYwXWNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The Random Forest Regressor aggregates predictions from multiple decision trees to leverage their collective knowledge and reduce overfitting.\n",
        " By averaging predictions or taking the median across the ensemble, the model achieves more stable and reliable predictions, making it a powerful tool for regression tasks in machine learning.\n",
        "\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "hV9lCU3VXX8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. What are the hyperparameters of Random Forest Regressor?"
      ],
      "metadata": {
        "id": "-ENXNerdXiyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "'n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf',  'max_features'\n",
        "\n",
        "\"\"\"\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Perform grid search\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsgvxKriXkKq",
        "outputId": "9925e5ce-e397-4198-ba9f-f2fc72c91836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?"
      ],
      "metadata": {
        "id": "mP3ySsSdYDgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Model Complexity:\n",
        "- Decision Tree Regressor: Simple, single tree structure.\n",
        "- Random Forest Regressor: Complex, ensemble of many trees.\n",
        "\n",
        "Training Method:\n",
        "- Decision Tree Regressor: Trained on the entire dataset without bootstrapping.\n",
        "- Random Forest Regressor: Uses bootstrap samples and random feature selection.\n",
        "\n",
        "Performance:\n",
        "- Decision Tree Regressor: High variance, prone to overfitting.\n",
        "- Random Forest Regressor: Reduced variance, less prone to overfitting, generally more accurate.\n",
        "\n",
        "Interpretability:\n",
        "- Decision Tree Regressor: Easier to interpret and visualize.\n",
        "- Random Forest Regressor: More difficult to interpret due to the ensemble of trees.\n",
        "\n",
        "Robustness and Generalization:\n",
        "- Decision Tree Regressor: Less robust, sensitive to data variations.\n",
        "- Random Forest Regressor: More robust, better generalization due to averaging of multiple trees.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vb4WOHasYHGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. What are the advantages and disadvantages of Random Forest Regressor?"
      ],
      "metadata": {
        "id": "j1XUyeMwY75C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Advantages:\n",
        "- Improved Accuracy: Typically provides better predictive performance than a single decision tree due to the ensemble effect.\n",
        "- Reduced Overfitting: Less prone to overfitting compared to a single decision tree.\n",
        "- Feature Importance: Can provide estimates of feature importance, which helps in understanding the influence of different features.\n",
        "\n",
        "Disadvantages:\n",
        "- Complexity: More complex to understand and visualize compared to a single decision tree.\n",
        "- Computationally Intensive: Requires more computational resources and memory due to the training and storage of multiple trees.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Z3PqUGXVY9no"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. What is the output of Random Forest Regressor?"
      ],
      "metadata": {
        "id": "tHTrP8kjZGmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The output of a Random Forest Regressor is a continuous numerical value, representing the predicted value for a given input instance.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LF5EzfEzZICa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. Can Random Forest Regressor be used for classification tasks?"
      ],
      "metadata": {
        "id": "lEK4QyISZMp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Yes, the Random Forest algorithm can be used for both regression and classification tasks, though the specific implementation and output differ between the two. The version of the Random Forest used for classification tasks is called the Random Forest Classifier.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zkiRhKoyZOj8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}